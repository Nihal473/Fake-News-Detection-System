{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a460b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwordcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07314f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real news: (21417, 5)\n",
      "Fake news: (23481, 5)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load datasets\n",
    "true_df = pd.read_csv(\"../data/True.csv\")\n",
    "fake_df = pd.read_csv(\"../data/Fake.csv\")\n",
    "\n",
    "true_df[\"label\"] = 1  # Real\n",
    "fake_df[\"label\"] = 0  # Fake\n",
    "\n",
    "print(\"Real news:\", true_df.shape)\n",
    "print(\"Fake news:\", fake_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Combine datasets\n",
    "df = pd.concat([true_df, fake_df], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "df = df[[\"text\", \"label\"]]\n",
    "df.dropna(inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Class balance\n",
    "sns.countplot(data=df, x=\"label\")\n",
    "plt.xticks([0, 1], [\"Fake\", \"Real\"])\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Function to clean text\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e36453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: WordCloud for Real News\n",
    "real_text = \" \".join(df[df.label == 1][\"clean_text\"])\n",
    "wordcloud_real = WordCloud(width=800, height=400, background_color=\"white\").generate(real_text)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud_real, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for Real News\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: WordCloud for Fake News\n",
    "fake_text = \" \".join(df[df.label == 0][\"clean_text\"])\n",
    "wordcloud_fake = WordCloud(width=800, height=400, background_color=\"white\").generate(fake_text)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud_fake, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for Fake News\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Most Common Words per class\n",
    "def get_top_words(text, n=20):\n",
    "    tokens = text.split()\n",
    "    counter = Counter(tokens)\n",
    "    return counter.most_common(n)\n",
    "\n",
    "print(\"Top 20 Real News Words:\")\n",
    "print(get_top_words(real_text))\n",
    "\n",
    "print(\"\\nTop 20 Fake News Words:\")\n",
    "print(get_top_words(fake_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: (Optional) Save cleaned CSV\n",
    "df.to_csv(\"../data/cleaned_news.csv\", index=False)\n",
    "print(\"Cleaned dataset saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
